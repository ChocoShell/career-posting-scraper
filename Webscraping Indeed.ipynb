{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around with this notebook https://github.com/rowandl/portfolio/blob/master/Webscraping%20Indeed.com/Webscraping%20Indeed.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, I will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "I am going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job I will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information, being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "I will convert this problem into classification and use a random forest classifier, as well as another classifier. \n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "I will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import urlopen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "html = urllib.urlopen(URL).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "len(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract each item: location, company, job, and salary.¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflocation = pd.DataFrame(columns=[\"location\"])\n",
    "dfcompany = pd.DataFrame(columns=[\"company\"])\n",
    "dfjob_title = pd.DataFrame(columns=[\"job_title\"])\n",
    "dfsalary = pd.DataFrame(columns=[\"salary\"])\n",
    "\n",
    "#result.find(‘a’,attrs={‘data-tn-element’:‘jobTitle’}).text\n",
    "def extract_location(result):\n",
    "    for b in result.find_all('span', {'class': 'location'}):\n",
    "        location = b.text\n",
    "        dflocation.loc[len(dflocation)] = [location]    \n",
    "        \n",
    "def extract_company(result):        \n",
    "    for i in result.find_all('span', {'class':'company'}):\n",
    "        company = i.text\n",
    "        dfcompany.loc[len(dfcompany)] = [company]   \n",
    "\n",
    "def extract_job_title(result):\n",
    "    for a in result.find_all('a', {'data-tn-element':'jobTitle'}):\n",
    "        job_title = a.text\n",
    "        dfjob_title.loc[len(dfjob_title)] = [job_title]\n",
    "\n",
    "def extract_salary(result):\n",
    "    for entry in result.find_all('td', {'class' : 'snip'}):\n",
    "        try:\n",
    "            salary = entry.find('nobr').text\n",
    "            dfsalary.loc[len(dfsalary)] = [salary]  \n",
    "        except:\n",
    "            salary = 'NA'\n",
    "            dfsalary.loc[len(dfsalary)] = [salary]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the l=New+York and the start=10. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list of cities to run through\n",
    "# 'New+York%2C+NY'\n",
    "cities = ['California', 'Texas', 'New+York+State']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe which collects all the information from my webscraping\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "query = \"data+scientist\"\n",
    "url_template= \"https://www.indeed.com/jobs?q={}&l={}&start={}\"\n",
    "max_results_per_city = 100 # Set this to a high-value to generate more results. \n",
    "\n",
    "df = pd.DataFrame(columns=[\"location\", 'company', 'job_title', 'salary'])\n",
    "def validator(elem):\n",
    "    if elem:\n",
    "        return elem.text\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "for city in cities:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_template.format(query,city,start)\n",
    "        html = urllib.urlopen(url).read()\n",
    "        soups = BeautifulSoup(html, \"html.parser\")\n",
    "#         with open('somefile.html', 'a') as the_file:\n",
    "#             the_file.write(str(soups))\n",
    "        rows = soups.find_all('div', attrs = {'class':'row'})\n",
    "        for b in rows:\n",
    "#             print(b)\n",
    "#             location = validator(b.find('div', attrs = {'class': 'location'}))\n",
    "            location = city\n",
    "            job_title = validator(b.find('a', attrs = {'data-tn-element':'jobTitle'}))\n",
    "            url = b.find('a', attrs = {'data-tn-element':'jobTitle'}).href\n",
    "            company = validator(b.find('span', attrs = {'class':'company'}))\n",
    "            salary = validator(b.find(name=\"span\", attrs={\"class\":\"no-wrap\"}))\n",
    "            summaries=\"\"\n",
    "            spans = b.findAll('span', attrs={'class': 'summary'})\n",
    "            for span in spans:\n",
    "                summaries += span.text.strip()\n",
    "            df = df.append({\"location\":location,\"company\":company, \"job_title\": job_title, \"salary\": salary, \"summary\": summaries, \"url\": url}, ignore_index=True) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True) #dropping duplicates\n",
    "df.company.replace(regex=True,inplace=True,to_replace=[\"\\n\", \"\\r\"],value=\"\") #getting rid of /n in company\n",
    "df.salary.replace(regex=True, inplace=True, to_replace=[\"\\n\", \"\\r\", \"\\$\"], value=\"\") #getting rid of $ in salary\n",
    "df.summary.replace(regex=True, inplace=True, to_replace=['\\.\\.\\.'], value=\"\") #getting rid of elipses in summary\n",
    "df.summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 5)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending it to csvs to save the data\n",
    "df.to_csv(\"~/Desktop/machineLearning.csv\" , sep=',', encoding='utf-8')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "df1 = pd.read_csv('~/Desktop/machineLearning.csv', index_col=0)\n",
    "# df2 = pd.read_csv('~/Desktop/GA/April11.csv')\n",
    "# df3 = pd.read_csv('~/Desktop/GA/April12.csv')\n",
    "# df4 = pd.read_csv('~/Desktop/GA/April1_11.csv')\n",
    "# df5 = pd.read_csv('~/Desktop/GA/April2_11.csv')\n",
    "# df6 = pd.read_csv('~/Desktop/GA/April_10.csv')\n",
    "# df7 = pd.read_csv('~/Desktop/GA/April_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df1]) #making into one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values \n",
      "location       0\n",
      "company        0\n",
      "job_title      0\n",
      "salary       326\n",
      "summary        0\n",
      "dtype: int64\n",
      "dataframe types \n",
      "location     object\n",
      "company      object\n",
      "job_title    object\n",
      "salary       object\n",
      "summary      object\n",
      "dtype: object\n",
      "dataframe shape \n",
      "(369, 5)\n",
      "dataframe describe \n",
      "          location         company       job_title  \\\n",
      "count          369             369             369   \n",
      "unique           3             303             215   \n",
      "top     California          Google  Data Scientist   \n",
      "freq           141               8             123   \n",
      "\n",
      "                                          salary  \\\n",
      "count                                         43   \n",
      "unique                                        38   \n",
      "top                     110,000 - 160,000 a year   \n",
      "freq                                           2   \n",
      "\n",
      "                                                  summary  \n",
      "count                                                 369  \n",
      "unique                                                345  \n",
      "top     Project experience in machine learning, comput...  \n",
      "freq                                                    4  \n",
      "dataframe length = 369\n",
      "duplicates 0\n",
      "location\n",
      "3\n",
      "company\n",
      "303\n",
      "job_title\n",
      "215\n",
      "salary\n",
      "38\n",
      "summary\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "def eda(dataframe): #code chunk to check quality of data\n",
    "    print \"missing values \\n\", dataframe.isnull().sum() #shows total amount of null values for each column\n",
    "    print \"dataframe types \\n\", dataframe.dtypes\n",
    "    print \"dataframe shape \\n\", dataframe.shape     \n",
    "    print \"dataframe describe \\n\", dataframe.describe()\n",
    "    print \"dataframe length =\", len(dataframe) #length of the dataframe\n",
    "    print \"duplicates\", dataframe.duplicated().sum() # added this to duplicates in the data\n",
    "    for item in dataframe:\n",
    "        print item\n",
    "        print dataframe[item].nunique()\n",
    "\n",
    "eda(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, I need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "I didn't think it was safe to multiply data for hour/week/month so I only wanted yearly data.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>Highlands Point Apartments</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>110,000 - 140,000 a year</td>\n",
       "      <td>If you are a Data Scientist with experience, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>California</td>\n",
       "      <td>Enrich Consulting, Inc.</td>\n",
       "      <td>Quantitative Modeler / Coder - Analyst</td>\n",
       "      <td>70,000 a year</td>\n",
       "      <td>As an Analyst, you will be customizing impleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>California</td>\n",
       "      <td>Negocios IT</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>130,000 - 150,000 a year</td>\n",
       "      <td>*Required skills:   3-5 years’ of experience. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>California</td>\n",
       "      <td>NESS USA INC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90,000 - 120,000 a year</td>\n",
       "      <td>Background in applied statistical modeling on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>California</td>\n",
       "      <td>Protein Metrics Inc.</td>\n",
       "      <td>Customer Success Scientist</td>\n",
       "      <td>120,000 - 140,000 a year</td>\n",
       "      <td>Our software allows scientists to use data the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>California</td>\n",
       "      <td>Stria</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>100,000 - 120,000 a year</td>\n",
       "      <td>We are looking for an accomplished data scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>California</td>\n",
       "      <td>Intro Staffing</td>\n",
       "      <td>Software Engineer - Autonomous Driving / Self ...</td>\n",
       "      <td>120,000 - 180,000 a year</td>\n",
       "      <td>Software Engineer - Autonomous Driving / Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>California</td>\n",
       "      <td>Lore IO</td>\n",
       "      <td>Python Developer</td>\n",
       "      <td>130,000 - 170,000 a year</td>\n",
       "      <td>We are experts in search, analytics, machine l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>California</td>\n",
       "      <td>FlowCommand Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>80,000 - 140,000 a year</td>\n",
       "      <td>Our sensors send ultrasonic data directly to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>California</td>\n",
       "      <td>Blue Owl</td>\n",
       "      <td>Actuarial Pricing Analyst</td>\n",
       "      <td>120,000 - 150,000 a year</td>\n",
       "      <td>We are a well funded team of elite developers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>California</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Data Scientist - Optimization</td>\n",
       "      <td>110,000 - 140,000 a year</td>\n",
       "      <td>Data Scientist - Optimization. So, if you are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>California</td>\n",
       "      <td>Top Biotechnology firm</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>45 - 50 an hour</td>\n",
       "      <td>The DMPK group works in close partnership with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>California</td>\n",
       "      <td>Blue Owl</td>\n",
       "      <td>Senior Business Analyst - Insurance</td>\n",
       "      <td>100,000 - 120,000 a year</td>\n",
       "      <td>To date, we have assembled a team of talented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Unique Software Development LLC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>80,000 - 140,000 a year</td>\n",
       "      <td>We are looking for three experienced Data Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Texas</td>\n",
       "      <td>BNSF</td>\n",
       "      <td>Intern - Fellow (Data Scientist) Summer 2019</td>\n",
       "      <td>45,760 - 54,080 a year</td>\n",
       "      <td>A Data Scientist Intern-Fellow’s work in the B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Deeter Investments LLP</td>\n",
       "      <td>Research Analyst In-House Counsel</td>\n",
       "      <td>80,000 - 110,000 a year</td>\n",
       "      <td>$80,000 – $110,000 commensurate with experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Texas</td>\n",
       "      <td>SSN Group</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70 - 75 an hour</td>\n",
       "      <td>Demonstrated experience and accomplishments in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Mercury Data Science</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>75,000 - 100,000 a year</td>\n",
       "      <td>Interest in data mining and machine learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Rekruiters</td>\n",
       "      <td>Solutions Architect</td>\n",
       "      <td>150,000 a year</td>\n",
       "      <td>Provide technical support to Project Managers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Protege</td>\n",
       "      <td>Core Data Scientist- medical research</td>\n",
       "      <td>120,000 a year</td>\n",
       "      <td>Demonstrated experience and accomplishments in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Fred's</td>\n",
       "      <td>Data Scientist, Forecasting &amp; Planning</td>\n",
       "      <td>87,000 - 129,000 a year (Indee...</td>\n",
       "      <td>Or Master’s Degree in a relevant technical fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Advantine Technologies</td>\n",
       "      <td>Data Scientist (MUST have minimum 5 years of e...</td>\n",
       "      <td>107,000 - 158,000 a year (Inde...</td>\n",
       "      <td>Grasp data that is available, pay attention to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Texas</td>\n",
       "      <td>National Oilwell Varco</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>93,000 - 137,000 a year (Indee...</td>\n",
       "      <td>PhD or Masters of Science in Physics, Mathemat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Texas</td>\n",
       "      <td>PepsiCo</td>\n",
       "      <td>Data Scientist - Security</td>\n",
       "      <td>113,000 - 167,000 a year (Inde...</td>\n",
       "      <td>This role will design and develop data models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Amne</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>87,000 - 128,000 a year (Indee...</td>\n",
       "      <td>As a Data Scientist at Amne, you’ll join a you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Universal Consulting Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>76,000 - 112,000 a year (Indee...</td>\n",
       "      <td>The Military Health System Management and Repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>88,000 - 129,000 a year (Indee...</td>\n",
       "      <td>You will be an expert in Big Data, Machine Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Funnel Science</td>\n",
       "      <td>Marketing Data Scientist</td>\n",
       "      <td>77,000 - 113,000 a year (Indee...</td>\n",
       "      <td>To apply, send a resume and cover note in an e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Mitel</td>\n",
       "      <td>Business Analyst/Data Scientist</td>\n",
       "      <td>90,000 - 133,000 a year (Indee...</td>\n",
       "      <td>Candidate must have a strong statistics backgr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Defined Clarity</td>\n",
       "      <td>Data Analyst / Data Scientist</td>\n",
       "      <td>65 - 75 an hour</td>\n",
       "      <td>Must be able to write SQL queries and must hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Gust</td>\n",
       "      <td>Inference Data Scientist</td>\n",
       "      <td>110,000 - 160,000 a year</td>\n",
       "      <td>Hands on experience in data science or analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>kapil.s@progressivestaffing.net</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>141,000 - 170,000 a year</td>\n",
       "      <td>Technical proficiency with optimizing data col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Net-Consultants</td>\n",
       "      <td>Machine Learning Data Scientist</td>\n",
       "      <td>110,000 - 150,000 a year</td>\n",
       "      <td>This is an exciting opportunity if you are int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Transfix.io</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>119,000 - 175,000 a year (Inde...</td>\n",
       "      <td>As a Data Scientist, you will implement machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Tilting Point</td>\n",
       "      <td>Game Data Scientist</td>\n",
       "      <td>99,000 - 146,000 a year (Indee...</td>\n",
       "      <td>Statistical, machine learning, and Bayesian kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Simon Property Group</td>\n",
       "      <td>Venture Capital Analyst - Data Scientist</td>\n",
       "      <td>110,000 - 162,000 a year (Inde...</td>\n",
       "      <td>Simon Ventures specializes in investing in nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>Data Scientist - Global Research &amp; Data Analyt...</td>\n",
       "      <td>133,000 - 196,000 a year (Inde...</td>\n",
       "      <td>The successful candidate will apply data analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Outbrain Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>105,000 - 155,000 a year (Inde...</td>\n",
       "      <td>Data Scientist (Sphere). Meaningful experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Vettery</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>94,000 - 139,000 a year (Indee...</td>\n",
       "      <td>Leveraging machine learning models that track ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>NewYork-Presbyterian Hospital</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>108,000 - 159,000 a year (Inde...</td>\n",
       "      <td>Our mission is to enhance healthcare delivery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Ezra Penland Actuarial Recruitment</td>\n",
       "      <td>Insurer seeks Health Actuary #82690</td>\n",
       "      <td>110,000 - 160,000 a year</td>\n",
       "      <td>FSA with 4 to 12 years of experience sought to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Pre-Sales Engineer</td>\n",
       "      <td>100,000 - 150,000 a year</td>\n",
       "      <td>You can have our machine learning algorithms a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>New+York+State</td>\n",
       "      <td>Net-Consultants</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>110,000 - 150,000 a year</td>\n",
       "      <td>This is an exciting opportunity if you are int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location                                     company  \\\n",
       "5        California                  Highlands Point Apartments   \n",
       "17       California                     Enrich Consulting, Inc.   \n",
       "24       California                                 Negocios IT   \n",
       "32       California                                NESS USA INC   \n",
       "34       California                        Protein Metrics Inc.   \n",
       "46       California                                       Stria   \n",
       "48       California                              Intro Staffing   \n",
       "51       California                                     Lore IO   \n",
       "66       California                            FlowCommand Inc.   \n",
       "93       California                                    Blue Owl   \n",
       "111      California                                 CyberCoders   \n",
       "125      California                      Top Biotechnology firm   \n",
       "156      California                                    Blue Owl   \n",
       "158           Texas             Unique Software Development LLC   \n",
       "167           Texas                                        BNSF   \n",
       "173           Texas                      Deeter Investments LLP   \n",
       "178           Texas                                   SSN Group   \n",
       "191           Texas                        Mercury Data Science   \n",
       "203           Texas                                  Rekruiters   \n",
       "219           Texas                                     Protege   \n",
       "240           Texas                                      Fred's   \n",
       "242           Texas                      Advantine Technologies   \n",
       "243           Texas                      National Oilwell Varco   \n",
       "244           Texas                                     PepsiCo   \n",
       "245           Texas                                        Amne   \n",
       "246           Texas               Universal Consulting Services   \n",
       "247           Texas                                     Verizon   \n",
       "248           Texas                              Funnel Science   \n",
       "249           Texas                                       Mitel   \n",
       "307  New+York+State                             Defined Clarity   \n",
       "317  New+York+State                                        Gust   \n",
       "338  New+York+State             kapil.s@progressivestaffing.net   \n",
       "345  New+York+State                             Net-Consultants   \n",
       "357  New+York+State                                 Transfix.io   \n",
       "358  New+York+State                               Tilting Point   \n",
       "360  New+York+State                        Simon Property Group   \n",
       "361  New+York+State                             JP Morgan Chase   \n",
       "362  New+York+State                               Outbrain Inc.   \n",
       "365  New+York+State                                     Vettery   \n",
       "366  New+York+State               NewYork-Presbyterian Hospital   \n",
       "383  New+York+State          Ezra Penland Actuarial Recruitment   \n",
       "398  New+York+State                                 CyberCoders   \n",
       "413  New+York+State                             Net-Consultants   \n",
       "\n",
       "                                             job_title  \\\n",
       "5                                       Data Scientist   \n",
       "17              Quantitative Modeler / Coder - Analyst   \n",
       "24                                      Data scientist   \n",
       "32                                      Data Scientist   \n",
       "34                          Customer Success Scientist   \n",
       "46                                      Data Scientist   \n",
       "48   Software Engineer - Autonomous Driving / Self ...   \n",
       "51                                    Python Developer   \n",
       "66                                      Data Scientist   \n",
       "93                           Actuarial Pricing Analyst   \n",
       "111                      Data Scientist - Optimization   \n",
       "125                                          Scientist   \n",
       "156                Senior Business Analyst - Insurance   \n",
       "158                                     Data Scientist   \n",
       "167       Intern - Fellow (Data Scientist) Summer 2019   \n",
       "173                  Research Analyst In-House Counsel   \n",
       "178                                     Data Scientist   \n",
       "191                                     Data Scientist   \n",
       "203                                Solutions Architect   \n",
       "219              Core Data Scientist- medical research   \n",
       "240             Data Scientist, Forecasting & Planning   \n",
       "242  Data Scientist (MUST have minimum 5 years of e...   \n",
       "243                                     Data Scientist   \n",
       "244                          Data Scientist - Security   \n",
       "245                                     Data Scientist   \n",
       "246                                     Data Scientist   \n",
       "247                                     Data Scientist   \n",
       "248                           Marketing Data Scientist   \n",
       "249                    Business Analyst/Data Scientist   \n",
       "307                      Data Analyst / Data Scientist   \n",
       "317                           Inference Data Scientist   \n",
       "338                                     Data Scientist   \n",
       "345                    Machine Learning Data Scientist   \n",
       "357                                     Data Scientist   \n",
       "358                                Game Data Scientist   \n",
       "360           Venture Capital Analyst - Data Scientist   \n",
       "361  Data Scientist - Global Research & Data Analyt...   \n",
       "362                                     Data Scientist   \n",
       "365                                     Data Scientist   \n",
       "366                                     Data Scientist   \n",
       "383                Insurer seeks Health Actuary #82690   \n",
       "398                                 Pre-Sales Engineer   \n",
       "413                                     Data Scientist   \n",
       "\n",
       "                                                salary  \\\n",
       "5                             110,000 - 140,000 a year   \n",
       "17                                       70,000 a year   \n",
       "24                            130,000 - 150,000 a year   \n",
       "32                             90,000 - 120,000 a year   \n",
       "34                            120,000 - 140,000 a year   \n",
       "46                            100,000 - 120,000 a year   \n",
       "48                            120,000 - 180,000 a year   \n",
       "51                            130,000 - 170,000 a year   \n",
       "66                             80,000 - 140,000 a year   \n",
       "93                            120,000 - 150,000 a year   \n",
       "111                           110,000 - 140,000 a year   \n",
       "125                                    45 - 50 an hour   \n",
       "156                           100,000 - 120,000 a year   \n",
       "158                            80,000 - 140,000 a year   \n",
       "167                             45,760 - 54,080 a year   \n",
       "173                            80,000 - 110,000 a year   \n",
       "178                                    70 - 75 an hour   \n",
       "191                            75,000 - 100,000 a year   \n",
       "203                                     150,000 a year   \n",
       "219                                     120,000 a year   \n",
       "240                  87,000 - 129,000 a year (Indee...   \n",
       "242                  107,000 - 158,000 a year (Inde...   \n",
       "243                  93,000 - 137,000 a year (Indee...   \n",
       "244                  113,000 - 167,000 a year (Inde...   \n",
       "245                  87,000 - 128,000 a year (Indee...   \n",
       "246                  76,000 - 112,000 a year (Indee...   \n",
       "247                  88,000 - 129,000 a year (Indee...   \n",
       "248                  77,000 - 113,000 a year (Indee...   \n",
       "249                  90,000 - 133,000 a year (Indee...   \n",
       "307                                    65 - 75 an hour   \n",
       "317                           110,000 - 160,000 a year   \n",
       "338                           141,000 - 170,000 a year   \n",
       "345                           110,000 - 150,000 a year   \n",
       "357                  119,000 - 175,000 a year (Inde...   \n",
       "358                  99,000 - 146,000 a year (Indee...   \n",
       "360                  110,000 - 162,000 a year (Inde...   \n",
       "361                  133,000 - 196,000 a year (Inde...   \n",
       "362                  105,000 - 155,000 a year (Inde...   \n",
       "365                  94,000 - 139,000 a year (Indee...   \n",
       "366                  108,000 - 159,000 a year (Inde...   \n",
       "383                           110,000 - 160,000 a year   \n",
       "398                           100,000 - 150,000 a year   \n",
       "413                           110,000 - 150,000 a year   \n",
       "\n",
       "                                               summary  \n",
       "5    If you are a Data Scientist with experience, p...  \n",
       "17   As an Analyst, you will be customizing impleme...  \n",
       "24   *Required skills:   3-5 years’ of experience. ...  \n",
       "32   Background in applied statistical modeling on ...  \n",
       "34   Our software allows scientists to use data the...  \n",
       "46   We are looking for an accomplished data scient...  \n",
       "48   Software Engineer - Autonomous Driving / Machi...  \n",
       "51   We are experts in search, analytics, machine l...  \n",
       "66   Our sensors send ultrasonic data directly to o...  \n",
       "93   We are a well funded team of elite developers,...  \n",
       "111  Data Scientist - Optimization. So, if you are ...  \n",
       "125  The DMPK group works in close partnership with...  \n",
       "156  To date, we have assembled a team of talented ...  \n",
       "158  We are looking for three experienced Data Scie...  \n",
       "167  A Data Scientist Intern-Fellow’s work in the B...  \n",
       "173  $80,000 – $110,000 commensurate with experienc...  \n",
       "178  Demonstrated experience and accomplishments in...  \n",
       "191  Interest in data mining and machine learning i...  \n",
       "203  Provide technical support to Project Managers,...  \n",
       "219  Demonstrated experience and accomplishments in...  \n",
       "240  Or Master’s Degree in a relevant technical fie...  \n",
       "242  Grasp data that is available, pay attention to...  \n",
       "243  PhD or Masters of Science in Physics, Mathemat...  \n",
       "244  This role will design and develop data models ...  \n",
       "245  As a Data Scientist at Amne, you’ll join a you...  \n",
       "246  The Military Health System Management and Repo...  \n",
       "247  You will be an expert in Big Data, Machine Lea...  \n",
       "248  To apply, send a resume and cover note in an e...  \n",
       "249  Candidate must have a strong statistics backgr...  \n",
       "307  Must be able to write SQL queries and must hav...  \n",
       "317  Hands on experience in data science or analyti...  \n",
       "338  Technical proficiency with optimizing data col...  \n",
       "345  This is an exciting opportunity if you are int...  \n",
       "357  As a Data Scientist, you will implement machin...  \n",
       "358  Statistical, machine learning, and Bayesian kn...  \n",
       "360  Simon Ventures specializes in investing in nex...  \n",
       "361  The successful candidate will apply data analy...  \n",
       "362  Data Scientist (Sphere). Meaningful experience...  \n",
       "365  Leveraging machine learning models that track ...  \n",
       "366  Our mission is to enhance healthcare delivery ...  \n",
       "383  FSA with 4 to 12 years of experience sought to...  \n",
       "398  You can have our machine learning algorithms a...  \n",
       "413  This is an exciting opportunity if you are int...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries = data[data.salary.notnull()]\n",
    "salaries = salaries[salaries.salary.str.contains('year')] #only getting yearly salaries\n",
    "#http://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex\n",
    "salaries.describe()\n",
    "data.dropna(axis=\"index\",subset=['salary'])\n",
    "# data[data.salary.notnull()].groupby(['salary'])['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 6)\n"
     ]
    }
   ],
   "source": [
    "#splitting my salaries to find an average\n",
    "salaries.salary.replace(regex=True, inplace=True, to_replace=\"a year\", value=\"\")\n",
    "salaries.salary.replace(regex=True, inplace=True, to_replace=\",\", value=\"\")\n",
    "salaries.salary.replace(regex=True, inplace=True, to_replace=\" \\(Indeed est.\\)\", value=\"\")\n",
    "salaries['salary_split'] = salaries['salary'].str.split('-')\n",
    "salaries.head()\n",
    "print(salaries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>salary_split</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>Highlands Point Apartments</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>110000 - 140000</td>\n",
       "      <td>If you are a Data Scientist with experience, p...</td>\n",
       "      <td>[                110000 ,  140000 ]</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>125000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>California</td>\n",
       "      <td>Enrich Consulting, Inc.</td>\n",
       "      <td>Quantitative Modeler / Coder - Analyst</td>\n",
       "      <td>70000</td>\n",
       "      <td>As an Analyst, you will be customizing impleme...</td>\n",
       "      <td>[                70000 ]</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>California</td>\n",
       "      <td>Negocios IT</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>130000 - 150000</td>\n",
       "      <td>*Required skills:   3-5 years’ of experience. ...</td>\n",
       "      <td>[                130000 ,  150000 ]</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>California</td>\n",
       "      <td>NESS USA INC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000 - 120000</td>\n",
       "      <td>Background in applied statistical modeling on ...</td>\n",
       "      <td>[                90000 ,  120000 ]</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>California</td>\n",
       "      <td>Protein Metrics Inc.</td>\n",
       "      <td>Customer Success Scientist</td>\n",
       "      <td>120000 - 140000</td>\n",
       "      <td>Our software allows scientists to use data the...</td>\n",
       "      <td>[                120000 ,  140000 ]</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location                             company  \\\n",
       "5   California          Highlands Point Apartments   \n",
       "17  California             Enrich Consulting, Inc.   \n",
       "24  California                         Negocios IT   \n",
       "32  California                        NESS USA INC   \n",
       "34  California                Protein Metrics Inc.   \n",
       "\n",
       "                                 job_title                            salary  \\\n",
       "5                           Data Scientist                  110000 - 140000    \n",
       "17  Quantitative Modeler / Coder - Analyst                            70000    \n",
       "24                          Data scientist                  130000 - 150000    \n",
       "32                          Data Scientist                   90000 - 120000    \n",
       "34              Customer Success Scientist                  120000 - 140000    \n",
       "\n",
       "                                              summary  \\\n",
       "5   If you are a Data Scientist with experience, p...   \n",
       "17  As an Analyst, you will be customizing impleme...   \n",
       "24  *Required skills:   3-5 years’ of experience. ...   \n",
       "32  Background in applied statistical modeling on ...   \n",
       "34  Our software allows scientists to use data the...   \n",
       "\n",
       "                           salary_split     lower     upper       avg  \n",
       "5   [                110000 ,  140000 ]  110000.0  140000.0  125000.0  \n",
       "17             [                70000 ]   70000.0       NaN   70000.0  \n",
       "24  [                130000 ,  150000 ]  130000.0  150000.0  140000.0  \n",
       "32   [                90000 ,  120000 ]   90000.0  120000.0  105000.0  \n",
       "34  [                120000 ,  140000 ]  120000.0  140000.0  130000.0  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding an average salary\n",
    "def avg(salaries):\n",
    "    salaries['lower'] = salaries['salary_split'].str[0].astype('float')\n",
    "    salaries['upper'] = salaries['salary_split'].str[1].astype('float')\n",
    "    salaries['avg'] = salaries[['lower','upper']].mean(axis=1)\n",
    "avg(salaries)\n",
    "salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 5)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping columns so I'm only left with average column\n",
    "clean_sal = salaries.drop(['salary','salary_split', 'lower', 'upper'], axis=1)\n",
    "clean_sal.head()\n",
    "clean_sal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>avg</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Highlands Point Apartments</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>If you are a Data Scientist with experience, p...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enrich Consulting, Inc.</td>\n",
       "      <td>Quantitative Modeler / Coder - Analyst</td>\n",
       "      <td>As an Analyst, you will be customizing impleme...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Negocios IT</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>*Required skills:   3-5 years’ of experience. ...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NESS USA INC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Background in applied statistical modeling on ...</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Protein Metrics Inc.</td>\n",
       "      <td>Customer Success Scientist</td>\n",
       "      <td>Our software allows scientists to use data the...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               company  \\\n",
       "5           Highlands Point Apartments   \n",
       "17             Enrich Consulting, Inc.   \n",
       "24                         Negocios IT   \n",
       "32                        NESS USA INC   \n",
       "34                Protein Metrics Inc.   \n",
       "\n",
       "                                 job_title  \\\n",
       "5                           Data Scientist   \n",
       "17  Quantitative Modeler / Coder - Analyst   \n",
       "24                          Data scientist   \n",
       "32                          Data Scientist   \n",
       "34              Customer Success Scientist   \n",
       "\n",
       "                                              summary       avg        city  \\\n",
       "5   If you are a Data Scientist with experience, p...  125000.0  California   \n",
       "17  As an Analyst, you will be customizing impleme...   70000.0  California   \n",
       "24  *Required skills:   3-5 years’ of experience. ...  140000.0  California   \n",
       "32  Background in applied statistical modeling on ...  105000.0  California   \n",
       "34  Our software allows scientists to use data the...  130000.0  California   \n",
       "\n",
       "   state  \n",
       "5    Cal  \n",
       "17   Cal  \n",
       "24   Cal  \n",
       "32   Cal  \n",
       "34   Cal  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sal['citystate'] = clean_sal['location'].str.split(',') #splitting the location to separate city and state\n",
    "# clean_sal['city'] = clean_sal['citystate'].str[0] #getting cities\n",
    "# clean_sal['state'] = clean_sal['citystate'].str[1] #getting states\n",
    "clean_sal['city'] = clean_sal['location'] #getting cities\n",
    "clean_sal['state'] = clean_sal['location'] #getting state\n",
    "clean_sal['state'] = clean_sal['state'].str[0:3] #getting only 2 letter state codes\n",
    "clean_sal.drop(['location','citystate'], axis=1, inplace=True) #dropping columns so I'm only left with cities/states\n",
    "clean_sal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values \n",
      "company      0\n",
      "job_title    0\n",
      "summary      0\n",
      "avg          0\n",
      "city         0\n",
      "state        0\n",
      "dtype: int64\n",
      "dataframe types \n",
      "company       object\n",
      "job_title     object\n",
      "summary       object\n",
      "avg          float64\n",
      "city          object\n",
      "state         object\n",
      "dtype: object\n",
      "dataframe shape \n",
      "(40, 6)\n",
      "dataframe describe \n",
      "                 avg\n",
      "count      40.000000\n",
      "mean   121123.000000\n",
      "std     23055.263174\n",
      "min     49920.000000\n",
      "25%    109625.000000\n",
      "50%    125000.000000\n",
      "75%    135000.000000\n",
      "max    164500.000000\n",
      "dataframe length = 40\n",
      "duplicates 0\n",
      "company\n",
      "37\n",
      "job_title\n",
      "25\n",
      "summary\n",
      "39\n",
      "avg\n",
      "26\n",
      "city\n",
      "3\n",
      "state\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "eda(clean_sal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "#saving my clean salary data to a csv\n",
    "clean_sal.to_csv(\"~/Desktop/clean_salary.csv\" , sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        40.000000\n",
       "mean     121123.000000\n",
       "std       23055.263174\n",
       "min       49920.000000\n",
       "25%      109625.000000\n",
       "50%      125000.000000\n",
       "75%      135000.000000\n",
       "max      164500.000000\n",
       "Name: avg, dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sal['avg'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125000.0\n",
      "Medians per city:\n",
      "city\n",
      "California        121666.666667\n",
      "New+York+State    135423.076923\n",
      "Texas             108294.666667\n",
      "Name: avg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#finding the median\n",
    "import numpy as np\n",
    "median = np.median(clean_sal.avg)\n",
    "print(median)\n",
    "\n",
    "print(\"Medians per city:\")\n",
    "print(clean_sal.groupby(['city'])['avg'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('~/Desktop/clean_salary.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>avg</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>dumsal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Gust</td>\n",
       "      <td>Inference Data Scientist</td>\n",
       "      <td>Hands on experience in data science or analyti...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>kapil.s@progressivestaffing.net</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Technical proficiency with optimizing data col...</td>\n",
       "      <td>155500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Net-Consultants</td>\n",
       "      <td>Machine Learning Data Scientist</td>\n",
       "      <td>This is an exciting opportunity if you are int...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Transfix.io</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>As a Data Scientist, you will implement machin...</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Tilting Point</td>\n",
       "      <td>Game Data Scientist</td>\n",
       "      <td>Statistical, machine learning, and Bayesian kn...</td>\n",
       "      <td>122500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Simon Property Group</td>\n",
       "      <td>Venture Capital Analyst - Data Scientist</td>\n",
       "      <td>Simon Ventures specializes in investing in nex...</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>Data Scientist - Global Research &amp; Data Analyt...</td>\n",
       "      <td>The successful candidate will apply data analy...</td>\n",
       "      <td>164500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Outbrain Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist (Sphere). Meaningful experience...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Vettery</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Leveraging machine learning models that track ...</td>\n",
       "      <td>116500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>NewYork-Presbyterian Hospital</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Our mission is to enhance healthcare delivery ...</td>\n",
       "      <td>133500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Ezra Penland Actuarial Recruitment</td>\n",
       "      <td>Insurer seeks Health Actuary #82690</td>\n",
       "      <td>FSA with 4 to 12 years of experience sought to...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Pre-Sales Engineer</td>\n",
       "      <td>You can have our machine learning algorithms a...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Net-Consultants</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>This is an exciting opportunity if you are int...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company  \\\n",
       "317                                        Gust   \n",
       "338             kapil.s@progressivestaffing.net   \n",
       "345                             Net-Consultants   \n",
       "357                                 Transfix.io   \n",
       "358                               Tilting Point   \n",
       "360                        Simon Property Group   \n",
       "361                             JP Morgan Chase   \n",
       "362                               Outbrain Inc.   \n",
       "365                                     Vettery   \n",
       "366               NewYork-Presbyterian Hospital   \n",
       "383          Ezra Penland Actuarial Recruitment   \n",
       "398                                 CyberCoders   \n",
       "413                             Net-Consultants   \n",
       "\n",
       "                                             job_title  \\\n",
       "317                           Inference Data Scientist   \n",
       "338                                     Data Scientist   \n",
       "345                    Machine Learning Data Scientist   \n",
       "357                                     Data Scientist   \n",
       "358                                Game Data Scientist   \n",
       "360           Venture Capital Analyst - Data Scientist   \n",
       "361  Data Scientist - Global Research & Data Analyt...   \n",
       "362                                     Data Scientist   \n",
       "365                                     Data Scientist   \n",
       "366                                     Data Scientist   \n",
       "383                Insurer seeks Health Actuary #82690   \n",
       "398                                 Pre-Sales Engineer   \n",
       "413                                     Data Scientist   \n",
       "\n",
       "                                               summary       avg  \\\n",
       "317  Hands on experience in data science or analyti...  135000.0   \n",
       "338  Technical proficiency with optimizing data col...  155500.0   \n",
       "345  This is an exciting opportunity if you are int...  130000.0   \n",
       "357  As a Data Scientist, you will implement machin...  147000.0   \n",
       "358  Statistical, machine learning, and Bayesian kn...  122500.0   \n",
       "360  Simon Ventures specializes in investing in nex...  136000.0   \n",
       "361  The successful candidate will apply data analy...  164500.0   \n",
       "362  Data Scientist (Sphere). Meaningful experience...  130000.0   \n",
       "365  Leveraging machine learning models that track ...  116500.0   \n",
       "366  Our mission is to enhance healthcare delivery ...  133500.0   \n",
       "383  FSA with 4 to 12 years of experience sought to...  135000.0   \n",
       "398  You can have our machine learning algorithms a...  125000.0   \n",
       "413  This is an exciting opportunity if you are int...  130000.0   \n",
       "\n",
       "               city state  dumsal  \n",
       "317  New+York+State   New       1  \n",
       "338  New+York+State   New       1  \n",
       "345  New+York+State   New       1  \n",
       "357  New+York+State   New       1  \n",
       "358  New+York+State   New       0  \n",
       "360  New+York+State   New       1  \n",
       "361  New+York+State   New       1  \n",
       "362  New+York+State   New       1  \n",
       "365  New+York+State   New       0  \n",
       "366  New+York+State   New       1  \n",
       "383  New+York+State   New       1  \n",
       "398  New+York+State   New       1  \n",
       "413  New+York+State   New       1  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['dumsal'] = (c[\"avg\"] >= c[\"avg\"].median()).astype(int)\n",
    "#http://stackoverflow.com/questions/36637011/how-can-i-create-a-dummy-variable-in-python-with-a-condition-below-or-above-medi\n",
    "c[c['state']==\"New\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer()\n",
    "X = c.summary\n",
    "y = c.dumsal\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english').fit(X_train)\n",
    "df_train = pd.DataFrame(cvec.transform(X_train).todense(),\n",
    "             columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 227)\n",
      "(26,)\n",
      "(14, 227)\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "print df_train.shape\n",
    "print y_train.shape\n",
    "print df_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(df_train, y_train)\n",
    "lr.score(df_test, y_test)\n",
    "#this is my title score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 1.   0.5  1.   0.   1.   0.   0.5]\n",
      "Cross-Predicted Accuracy: 0.571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "cv = 7\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(lr, df_test, y_test, cv=cv)\n",
    "print \"Cross-validated scores:\", scores\n",
    "# Make cross validated predictions\n",
    "predictions = cross_val_predict(lr, df_test, y_test, cv=cv)\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print \"Cross-Predicted Accuracy:\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Score:\t0.5 ± 0.045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "RF = rf.fit(df_train,y_train)\n",
    "s = cross_val_score(rf, df_train, y_train, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Random Forrest\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.061869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumer</th>\n",
       "      <td>0.038589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exciting</th>\n",
       "      <td>0.038514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <td>0.037125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>0.034248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>areas</th>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chosen</th>\n",
       "      <td>0.029344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>millions</th>\n",
       "      <td>0.025356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plans</th>\n",
       "      <td>0.024385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>0.023204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance\n",
       "scientist     0.061869\n",
       "consumer      0.038589\n",
       "exciting      0.038514\n",
       "algorithms    0.037125\n",
       "machine       0.034248\n",
       "areas         0.029412\n",
       "chosen        0.029344\n",
       "millions      0.025356\n",
       "plans         0.024385\n",
       "business      0.023204"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_features = pd.DataFrame(RF.feature_importances_,\n",
    "                                   index = df_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "rf_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in my dataframe to represent interesting features of a job title. Then I built a new Random Forest with these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>avg</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>dumsal</th>\n",
       "      <th>visualization</th>\n",
       "      <th>manager</th>\n",
       "      <th>scientist</th>\n",
       "      <th>associate</th>\n",
       "      <th>machine</th>\n",
       "      <th>learning</th>\n",
       "      <th>engineer</th>\n",
       "      <th>senior</th>\n",
       "      <th>mining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Highlands Point Apartments</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enrich Consulting, Inc.</td>\n",
       "      <td>Quantitative Modeler / Coder - Analyst</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Negocios IT</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NESS USA INC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Protein Metrics Inc.</td>\n",
       "      <td>Customer Success Scientist</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               company  \\\n",
       "5           Highlands Point Apartments   \n",
       "17             Enrich Consulting, Inc.   \n",
       "24                         Negocios IT   \n",
       "32                        NESS USA INC   \n",
       "34                Protein Metrics Inc.   \n",
       "\n",
       "                                 job_title       avg        city state  \\\n",
       "5                           Data Scientist  125000.0  California   Cal   \n",
       "17  Quantitative Modeler / Coder - Analyst   70000.0  California   Cal   \n",
       "24                          Data scientist  140000.0  California   Cal   \n",
       "32                          Data Scientist  105000.0  California   Cal   \n",
       "34              Customer Success Scientist  130000.0  California   Cal   \n",
       "\n",
       "    dumsal  visualization  manager  scientist  associate  machine  learning  \\\n",
       "5        1              0        0          1          0        0         0   \n",
       "17       0              0        0          0          0        0         0   \n",
       "24       1              0        0          0          0        0         0   \n",
       "32       0              0        0          0          0        0         0   \n",
       "34       1              0        0          1          0        0         0   \n",
       "\n",
       "    engineer  senior  mining  \n",
       "5          0       0       0  \n",
       "17         0       0       0  \n",
       "24         0       0       0  \n",
       "32         0       0       0  \n",
       "34         0       0       0  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manager, visualization, scientist, engineer, analyst, senior\n",
    "vect_col = 'summary'\n",
    "c['visualization'] = map(int, c[vect_col].str.lower().str.contains('vis'))\n",
    "c['manager'] = map(int, c[vect_col].str.lower().str.contains('manager')|\n",
    "                  c[vect_col].str.lower().str.contains('mngr')|\n",
    "                  c[vect_col].str.lower().str.contains('mgr'))\n",
    "c['scientist'] = map(int, c[vect_col].str.lower().str.contains('scien'))\n",
    "c['associate'] = map(int, c[vect_col].str.lower().str.contains('asso'))\n",
    "c['machine'] = map(int, c[vect_col].str.lower().str.contains('mach'))\n",
    "c['learning'] = map(int, c[vect_col].str.lower().str.contains('lear'))\n",
    "c['mining'] = map(int, c[vect_col].str.lower().str.contains('minin'))\n",
    "c['engineer'] = map(int, c[vect_col].str.lower().str.contains('engi')|\n",
    "                         c[vect_col].str.lower().str.contains('engr'))\n",
    "c['senior'] = map(int, c[vect_col].str.lower().str.contains('sr')|\n",
    "                  c[vect_col].str.lower().str.contains('snr')|\n",
    "                  c[vect_col].str.lower().str.contains('senior'))\n",
    "#making dummies for the words at the top of this cell\n",
    "c.loc[:, c.columns != 'summary'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#completing a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = c[['manager', 'visualization', 'scientist', 'engineer', 'senior', 'associate', 'mining']]\n",
    "y = c.dumsal\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)\n",
    "#this is my concatonated score since it's worse I'm only going to use  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Score:\t0.575 ± 0.032\n"
     ]
    }
   ],
   "source": [
    "#and a random forest classifier\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "s = cross_val_score(rf, X, y, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Random Forrest\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4c54e0b18594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Perform 6-fold cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Cross-validated scores:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Make cross validated predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(rf, X, y, cv=6)\n",
    "print \"Cross-validated scores:\", scores\n",
    "# Make cross validated predictions\n",
    "predictions = cross_val_predict(rf, X, y, cv=6)\n",
    "accuracy = metrics.accuracy_score(y, predictions)\n",
    "print \"Cross-Predicted Accuracy:\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "#sending my final to a csv\n",
    "c.to_csv(\"~/Desktop/c.csv\" , sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>avg</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>dumsal</th>\n",
       "      <th>visualization</th>\n",
       "      <th>manager</th>\n",
       "      <th>scientist</th>\n",
       "      <th>associate</th>\n",
       "      <th>machine</th>\n",
       "      <th>learning</th>\n",
       "      <th>engineer</th>\n",
       "      <th>senior</th>\n",
       "      <th>mining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Highlands Point Apartments</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>If you are a Data Scientist with experience, p...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enrich Consulting, Inc.</td>\n",
       "      <td>Quantitative Modeler / Coder - Analyst</td>\n",
       "      <td>As an Analyst, you will be customizing impleme...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Negocios IT</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>*Required skills:   3-5 years’ of experience. ...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NESS USA INC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Background in applied statistical modeling on ...</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Protein Metrics Inc.</td>\n",
       "      <td>Customer Success Scientist</td>\n",
       "      <td>Our software allows scientists to use data the...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Stria</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>We are looking for an accomplished data scient...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Intro Staffing</td>\n",
       "      <td>Software Engineer - Autonomous Driving / Self ...</td>\n",
       "      <td>Software Engineer - Autonomous Driving / Machi...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Lore IO</td>\n",
       "      <td>Python Developer</td>\n",
       "      <td>We are experts in search, analytics, machine l...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>FlowCommand Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Our sensors send ultrasonic data directly to o...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Blue Owl</td>\n",
       "      <td>Actuarial Pricing Analyst</td>\n",
       "      <td>We are a well funded team of elite developers,...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Data Scientist - Optimization</td>\n",
       "      <td>Data Scientist - Optimization. So, if you are ...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Blue Owl</td>\n",
       "      <td>Senior Business Analyst - Insurance</td>\n",
       "      <td>To date, we have assembled a team of talented ...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Unique Software Development LLC</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>We are looking for three experienced Data Scie...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>BNSF</td>\n",
       "      <td>Intern - Fellow (Data Scientist) Summer 2019</td>\n",
       "      <td>A Data Scientist Intern-Fellow’s work in the B...</td>\n",
       "      <td>49920.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Deeter Investments LLP</td>\n",
       "      <td>Research Analyst In-House Counsel</td>\n",
       "      <td>$80,000 – $110,000 commensurate with experienc...</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Mercury Data Science</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Interest in data mining and machine learning i...</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Rekruiters</td>\n",
       "      <td>Solutions Architect</td>\n",
       "      <td>Provide technical support to Project Managers,...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Protege</td>\n",
       "      <td>Core Data Scientist- medical research</td>\n",
       "      <td>Demonstrated experience and accomplishments in...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Fred's</td>\n",
       "      <td>Data Scientist, Forecasting &amp; Planning</td>\n",
       "      <td>Or Master’s Degree in a relevant technical fie...</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Advantine Technologies</td>\n",
       "      <td>Data Scientist (MUST have minimum 5 years of e...</td>\n",
       "      <td>Grasp data that is available, pay attention to...</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>National Oilwell Varco</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PhD or Masters of Science in Physics, Mathemat...</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>PepsiCo</td>\n",
       "      <td>Data Scientist - Security</td>\n",
       "      <td>This role will design and develop data models ...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Amne</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>As a Data Scientist at Amne, you’ll join a you...</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Universal Consulting Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The Military Health System Management and Repo...</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>You will be an expert in Big Data, Machine Lea...</td>\n",
       "      <td>108500.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Funnel Science</td>\n",
       "      <td>Marketing Data Scientist</td>\n",
       "      <td>To apply, send a resume and cover note in an e...</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Mitel</td>\n",
       "      <td>Business Analyst/Data Scientist</td>\n",
       "      <td>Candidate must have a strong statistics backgr...</td>\n",
       "      <td>111500.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Gust</td>\n",
       "      <td>Inference Data Scientist</td>\n",
       "      <td>Hands on experience in data science or analyti...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>kapil.s@progressivestaffing.net</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Technical proficiency with optimizing data col...</td>\n",
       "      <td>155500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Net-Consultants</td>\n",
       "      <td>Machine Learning Data Scientist</td>\n",
       "      <td>This is an exciting opportunity if you are int...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Transfix.io</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>As a Data Scientist, you will implement machin...</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Tilting Point</td>\n",
       "      <td>Game Data Scientist</td>\n",
       "      <td>Statistical, machine learning, and Bayesian kn...</td>\n",
       "      <td>122500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Simon Property Group</td>\n",
       "      <td>Venture Capital Analyst - Data Scientist</td>\n",
       "      <td>Simon Ventures specializes in investing in nex...</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>Data Scientist - Global Research &amp; Data Analyt...</td>\n",
       "      <td>The successful candidate will apply data analy...</td>\n",
       "      <td>164500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Outbrain Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist (Sphere). Meaningful experience...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Vettery</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Leveraging machine learning models that track ...</td>\n",
       "      <td>116500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>NewYork-Presbyterian Hospital</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Our mission is to enhance healthcare delivery ...</td>\n",
       "      <td>133500.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Ezra Penland Actuarial Recruitment</td>\n",
       "      <td>Insurer seeks Health Actuary #82690</td>\n",
       "      <td>FSA with 4 to 12 years of experience sought to...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Pre-Sales Engineer</td>\n",
       "      <td>You can have our machine learning algorithms a...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Net-Consultants</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>This is an exciting opportunity if you are int...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New+York+State</td>\n",
       "      <td>New</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company  \\\n",
       "5                    Highlands Point Apartments   \n",
       "17                      Enrich Consulting, Inc.   \n",
       "24                                  Negocios IT   \n",
       "32                                 NESS USA INC   \n",
       "34                         Protein Metrics Inc.   \n",
       "46                                        Stria   \n",
       "48                               Intro Staffing   \n",
       "51                                      Lore IO   \n",
       "66                             FlowCommand Inc.   \n",
       "93                                     Blue Owl   \n",
       "111                                 CyberCoders   \n",
       "156                                    Blue Owl   \n",
       "158             Unique Software Development LLC   \n",
       "167                                        BNSF   \n",
       "173                      Deeter Investments LLP   \n",
       "191                        Mercury Data Science   \n",
       "203                                  Rekruiters   \n",
       "219                                     Protege   \n",
       "240                                      Fred's   \n",
       "242                      Advantine Technologies   \n",
       "243                      National Oilwell Varco   \n",
       "244                                     PepsiCo   \n",
       "245                                        Amne   \n",
       "246               Universal Consulting Services   \n",
       "247                                     Verizon   \n",
       "248                              Funnel Science   \n",
       "249                                       Mitel   \n",
       "317                                        Gust   \n",
       "338             kapil.s@progressivestaffing.net   \n",
       "345                             Net-Consultants   \n",
       "357                                 Transfix.io   \n",
       "358                               Tilting Point   \n",
       "360                        Simon Property Group   \n",
       "361                             JP Morgan Chase   \n",
       "362                               Outbrain Inc.   \n",
       "365                                     Vettery   \n",
       "366               NewYork-Presbyterian Hospital   \n",
       "383          Ezra Penland Actuarial Recruitment   \n",
       "398                                 CyberCoders   \n",
       "413                             Net-Consultants   \n",
       "\n",
       "                                             job_title  \\\n",
       "5                                       Data Scientist   \n",
       "17              Quantitative Modeler / Coder - Analyst   \n",
       "24                                      Data scientist   \n",
       "32                                      Data Scientist   \n",
       "34                          Customer Success Scientist   \n",
       "46                                      Data Scientist   \n",
       "48   Software Engineer - Autonomous Driving / Self ...   \n",
       "51                                    Python Developer   \n",
       "66                                      Data Scientist   \n",
       "93                           Actuarial Pricing Analyst   \n",
       "111                      Data Scientist - Optimization   \n",
       "156                Senior Business Analyst - Insurance   \n",
       "158                                     Data Scientist   \n",
       "167       Intern - Fellow (Data Scientist) Summer 2019   \n",
       "173                  Research Analyst In-House Counsel   \n",
       "191                                     Data Scientist   \n",
       "203                                Solutions Architect   \n",
       "219              Core Data Scientist- medical research   \n",
       "240             Data Scientist, Forecasting & Planning   \n",
       "242  Data Scientist (MUST have minimum 5 years of e...   \n",
       "243                                     Data Scientist   \n",
       "244                          Data Scientist - Security   \n",
       "245                                     Data Scientist   \n",
       "246                                     Data Scientist   \n",
       "247                                     Data Scientist   \n",
       "248                           Marketing Data Scientist   \n",
       "249                    Business Analyst/Data Scientist   \n",
       "317                           Inference Data Scientist   \n",
       "338                                     Data Scientist   \n",
       "345                    Machine Learning Data Scientist   \n",
       "357                                     Data Scientist   \n",
       "358                                Game Data Scientist   \n",
       "360           Venture Capital Analyst - Data Scientist   \n",
       "361  Data Scientist - Global Research & Data Analyt...   \n",
       "362                                     Data Scientist   \n",
       "365                                     Data Scientist   \n",
       "366                                     Data Scientist   \n",
       "383                Insurer seeks Health Actuary #82690   \n",
       "398                                 Pre-Sales Engineer   \n",
       "413                                     Data Scientist   \n",
       "\n",
       "                                               summary       avg  \\\n",
       "5    If you are a Data Scientist with experience, p...  125000.0   \n",
       "17   As an Analyst, you will be customizing impleme...   70000.0   \n",
       "24   *Required skills:   3-5 years’ of experience. ...  140000.0   \n",
       "32   Background in applied statistical modeling on ...  105000.0   \n",
       "34   Our software allows scientists to use data the...  130000.0   \n",
       "46   We are looking for an accomplished data scient...  110000.0   \n",
       "48   Software Engineer - Autonomous Driving / Machi...  150000.0   \n",
       "51   We are experts in search, analytics, machine l...  150000.0   \n",
       "66   Our sensors send ultrasonic data directly to o...  110000.0   \n",
       "93   We are a well funded team of elite developers,...  135000.0   \n",
       "111  Data Scientist - Optimization. So, if you are ...  125000.0   \n",
       "156  To date, we have assembled a team of talented ...  110000.0   \n",
       "158  We are looking for three experienced Data Scie...  110000.0   \n",
       "167  A Data Scientist Intern-Fellow’s work in the B...   49920.0   \n",
       "173  $80,000 – $110,000 commensurate with experienc...   95000.0   \n",
       "191  Interest in data mining and machine learning i...   87500.0   \n",
       "203  Provide technical support to Project Managers,...  150000.0   \n",
       "219  Demonstrated experience and accomplishments in...  120000.0   \n",
       "240  Or Master’s Degree in a relevant technical fie...  108000.0   \n",
       "242  Grasp data that is available, pay attention to...  132500.0   \n",
       "243  PhD or Masters of Science in Physics, Mathemat...  115000.0   \n",
       "244  This role will design and develop data models ...  140000.0   \n",
       "245  As a Data Scientist at Amne, you’ll join a you...  107500.0   \n",
       "246  The Military Health System Management and Repo...   94000.0   \n",
       "247  You will be an expert in Big Data, Machine Lea...  108500.0   \n",
       "248  To apply, send a resume and cover note in an e...   95000.0   \n",
       "249  Candidate must have a strong statistics backgr...  111500.0   \n",
       "317  Hands on experience in data science or analyti...  135000.0   \n",
       "338  Technical proficiency with optimizing data col...  155500.0   \n",
       "345  This is an exciting opportunity if you are int...  130000.0   \n",
       "357  As a Data Scientist, you will implement machin...  147000.0   \n",
       "358  Statistical, machine learning, and Bayesian kn...  122500.0   \n",
       "360  Simon Ventures specializes in investing in nex...  136000.0   \n",
       "361  The successful candidate will apply data analy...  164500.0   \n",
       "362  Data Scientist (Sphere). Meaningful experience...  130000.0   \n",
       "365  Leveraging machine learning models that track ...  116500.0   \n",
       "366  Our mission is to enhance healthcare delivery ...  133500.0   \n",
       "383  FSA with 4 to 12 years of experience sought to...  135000.0   \n",
       "398  You can have our machine learning algorithms a...  125000.0   \n",
       "413  This is an exciting opportunity if you are int...  130000.0   \n",
       "\n",
       "               city state  dumsal  visualization  manager  scientist  \\\n",
       "5        California   Cal       1              0        0          1   \n",
       "17       California   Cal       0              0        0          0   \n",
       "24       California   Cal       1              0        0          0   \n",
       "32       California   Cal       0              0        0          0   \n",
       "34       California   Cal       1              0        0          1   \n",
       "46       California   Cal       0              0        0          1   \n",
       "48       California   Cal       1              0        0          0   \n",
       "51       California   Cal       1              0        0          0   \n",
       "66       California   Cal       0              0        0          1   \n",
       "93       California   Cal       1              0        0          1   \n",
       "111      California   Cal       1              0        0          1   \n",
       "156      California   Cal       0              0        0          1   \n",
       "158           Texas   Tex       0              0        0          1   \n",
       "167           Texas   Tex       0              0        0          1   \n",
       "173           Texas   Tex       0              0        0          0   \n",
       "191           Texas   Tex       0              0        0          0   \n",
       "203           Texas   Tex       1              0        1          1   \n",
       "219           Texas   Tex       0              0        0          0   \n",
       "240           Texas   Tex       0              0        0          1   \n",
       "242           Texas   Tex       1              0        0          0   \n",
       "243           Texas   Tex       0              0        0          1   \n",
       "244           Texas   Tex       1              0        0          0   \n",
       "245           Texas   Tex       0              0        0          1   \n",
       "246           Texas   Tex       0              0        0          0   \n",
       "247           Texas   Tex       0              0        0          0   \n",
       "248           Texas   Tex       0              0        0          0   \n",
       "249           Texas   Tex       0              0        0          0   \n",
       "317  New+York+State   New       1              0        0          1   \n",
       "338  New+York+State   New       1              0        0          0   \n",
       "345  New+York+State   New       1              0        0          1   \n",
       "357  New+York+State   New       1              0        0          1   \n",
       "358  New+York+State   New       0              0        0          0   \n",
       "360  New+York+State   New       1              0        0          0   \n",
       "361  New+York+State   New       1              0        0          0   \n",
       "362  New+York+State   New       1              0        0          1   \n",
       "365  New+York+State   New       0              0        0          0   \n",
       "366  New+York+State   New       1              0        0          0   \n",
       "383  New+York+State   New       1              0        0          1   \n",
       "398  New+York+State   New       1              0        0          0   \n",
       "413  New+York+State   New       1              0        0          1   \n",
       "\n",
       "     associate  machine  learning  engineer  senior  mining  \n",
       "5            0        0         0         0       0       0  \n",
       "17           0        0         0         0       0       0  \n",
       "24           0        0         0         0       0       0  \n",
       "32           0        0         0         0       0       0  \n",
       "34           0        0         0         0       0       0  \n",
       "46           0        0         0         0       0       0  \n",
       "48           0        1         1         1       0       0  \n",
       "51           0        1         1         0       0       1  \n",
       "66           0        0         0         0       0       0  \n",
       "93           0        0         0         0       0       0  \n",
       "111          0        0         0         0       0       0  \n",
       "156          0        0         0         1       0       0  \n",
       "158          0        0         0         0       0       0  \n",
       "167          0        0         0         0       0       0  \n",
       "173          0        0         0         0       0       0  \n",
       "191          0        1         1         0       0       1  \n",
       "203          0        0         0         0       0       0  \n",
       "219          0        1         1         0       0       1  \n",
       "240          0        0         0         1       0       0  \n",
       "242          0        0         1         0       0       0  \n",
       "243          0        0         0         1       0       0  \n",
       "244          0        1         1         0       0       0  \n",
       "245          0        0         0         0       0       0  \n",
       "246          0        0         0         0       0       0  \n",
       "247          0        1         1         0       0       0  \n",
       "248          0        0         0         0       0       0  \n",
       "249          0        1         0         0       0       0  \n",
       "317          0        0         0         0       0       0  \n",
       "338          0        0         0         0       0       1  \n",
       "345          0        1         0         0       0       0  \n",
       "357          0        1         1         0       0       0  \n",
       "358          0        1         1         0       0       0  \n",
       "360          0        0         0         0       0       0  \n",
       "361          0        1         1         1       0       0  \n",
       "362          0        1         1         0       0       0  \n",
       "365          0        1         1         0       0       0  \n",
       "366          0        1         1         0       0       0  \n",
       "383          0        0         0         0       0       0  \n",
       "398          0        1         1         0       0       0  \n",
       "413          0        1         0         0       0       0  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"~/Desktop/c.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
